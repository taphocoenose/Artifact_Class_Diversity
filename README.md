# Artifact Class Diversity
This project contains R and Stan (www.mc-stan.org) scripts that estimate artifact class diversity in multiple geographic regions.<br><br>

<b>Point_Diversity.R</b><br>
This script requires two csv files: <i>geog_data.csv</i> and <i>point_data.csv</i>. The former csv file contains a row for every administrative unit under consideration (e.g., counties, states), with the first column consisting of unique administrative unit IDs. If the data under consideration come from the United States, I recommend using county/state FIPS codes in this column. Each succeeing column represents a geographic zone of interest, where values represent the area of the zone represented within each county. Area can be represented in any spatial unit. <i>point_data.csv</i> also begins with a column of administrative unit IDs. Every ID in <i>point_data.csv</i> should be present in <i>geog_data.csv</i> (i.e., there must be a way to tie every artifact observation to a geographic zones). Each subsequent column consists of an artifact class, with counts of that class within each administrative unit. Ensure that these two csv files are in your working directory before running the script. For the examples presented by Boulanger et al. at the 2019 SAA meetings, please contact Matt Boulanger (mboulanger@smu.edu) for the appropriate csv tables.<br><br>

<i>Point_Diversity.R</i> preprocesses the csv data and proceeds to fit Stan models to <i>n</i> (user-specified) dataset permutations. For data-rich scenarios (i.e., moderate to large numbers of observed point counts for each geographic zone), one dataset permutation can be fitted in less than five minutes. In these scenarios, it may be possible to fit up to 100 dataset permutations on a personal computer in a reasonable amount of time. Note that this runs as a parallel process, where each model is fit on one core (the code defaults to four Hamiltonian Monte Carlo [HMC] chains per model. These are fit serially on each node). As such, quad-core machines will have significant speed advantages over dual-core machines. For larger numbers of dataets permutations (i.e., 100+), running this script on a cluster node will provide dramatic speed advantages.<br><br>

Note that model fitting speed generally depends on the amount of available data. If the dataset is dominated by regions with few observed artifacts (i.e., where most classes have 0 observations), it will take longer for Stan HMC simulations to explore the posterior distribution. This inefficiency will be visible in parameter estimates with low effective samples and posteriors will be vague, possibly too vague for useful inferences. In these cases, I recommend rethinking your approach, either by reducing the number of artifact classes or number of geographic zones. Although these scripts can handle uneven sampling between regions and recurring 0-count observations, it cannot provide informative inferences if there simply are not much data. For the large-scale phsyiographic example detailed by Boulanger et al. (2019 SAA meetings), we had 1200+ observations, 5 geographic zones, and 32 artifact classes. Most dataset permutations had at least one observed artifact for 12-32 classes in each zone. We found that this provided reasonably informative posterior estimates of class diversity in each zone.<br><br>
